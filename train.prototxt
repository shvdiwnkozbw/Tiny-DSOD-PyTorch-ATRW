name: "DCOD300_tiger02_DCOD300_300x300_train"
layer {
  name: "data"
  type: "AnnotatedData"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_value: 104.0
    mean_value: 117.0
    mean_value: 123.0
    resize_param {
      prob: 1.0
      resize_mode: WARP
      height: 300
      width: 300
      interp_mode: LINEAR
      interp_mode: AREA
      interp_mode: NEAREST
      interp_mode: CUBIC
      interp_mode: LANCZOS4
    }
    emit_constraint {
      emit_type: CENTER
    }
    distort_param {
      brightness_prob: 0.5
      brightness_delta: 32.0
      contrast_prob: 0.5
      contrast_lower: 0.5
      contrast_upper: 1.5
      hue_prob: 0.5
      hue_delta: 18.0
      saturation_prob: 0.5
      saturation_lower: 0.5
      saturation_upper: 1.5
      random_order_prob: 0.0
    }
    expand_param {
      prob: 0.5
      max_expand_ratio: 4.0
    }
  }
  data_param {
    source: "examples/tiger02/tiger02_trainval_lmdb"
    batch_size: 8
    backend: LMDB
  }
  annotated_data_param {
    batch_sampler {
      max_sample: 1
      max_trials: 1
    }
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.10000000149011612
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.30000001192092896
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.5
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.699999988079071
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        min_jaccard_overlap: 0.8999999761581421
      }
      max_sample: 1
      max_trials: 50
    }
    batch_sampler {
      sampler {
        min_scale: 0.30000001192092896
        max_scale: 1.0
        min_aspect_ratio: 0.5
        max_aspect_ratio: 2.0
      }
      sample_constraint {
        max_jaccard_overlap: 1.0
      }
      max_sample: 1
      max_trials: 50
    }
    label_map_file: "data/tiger02/labelmap.prototxt"
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "BatchNorm1"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "BatchNorm1"
  top: "BatchNorm1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "BatchNorm1"
  top: "Convolution2"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ConvolutionDepthwise1"
  type: "ConvolutionDepthwise"
  bottom: "Convolution2"
  top: "ConvolutionDepthwise1"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise1"
  top: "BatchNorm2"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "BatchNorm2"
  top: "BatchNorm2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "BatchNorm2"
  top: "Convolution3"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ConvolutionDepthwise2"
  type: "ConvolutionDepthwise"
  bottom: "Convolution3"
  top: "ConvolutionDepthwise2"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise2"
  top: "BatchNorm3"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "BatchNorm3"
  top: "BatchNorm3"
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "BatchNorm3"
  top: "Pooling1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Pooling1"
  top: "Convolution4"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise3"
  type: "ConvolutionDepthwise"
  bottom: "Convolution4"
  top: "ConvolutionDepthwise3"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise3"
  top: "ConvolutionDepthwise3"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "ConvolutionDepthwise3"
  top: "ConvolutionDepthwise3"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "ConvolutionDepthwise3"
  top: "ConvolutionDepthwise3"
}
layer {
  name: "Concat1"
  type: "Concat"
  bottom: "Pooling1"
  bottom: "ConvolutionDepthwise3"
  top: "Concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Concat1"
  top: "Convolution5"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise4"
  type: "ConvolutionDepthwise"
  bottom: "Convolution5"
  top: "ConvolutionDepthwise4"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise4"
  top: "ConvolutionDepthwise4"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "ConvolutionDepthwise4"
  top: "ConvolutionDepthwise4"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "ConvolutionDepthwise4"
  top: "ConvolutionDepthwise4"
}
layer {
  name: "Concat2"
  type: "Concat"
  bottom: "Concat1"
  bottom: "ConvolutionDepthwise4"
  top: "Concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Concat2"
  top: "Convolution6"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise5"
  type: "ConvolutionDepthwise"
  bottom: "Convolution6"
  top: "ConvolutionDepthwise5"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise5"
  top: "ConvolutionDepthwise5"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "ConvolutionDepthwise5"
  top: "ConvolutionDepthwise5"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "ConvolutionDepthwise5"
  top: "ConvolutionDepthwise5"
}
layer {
  name: "Concat3"
  type: "Concat"
  bottom: "Concat2"
  bottom: "ConvolutionDepthwise5"
  top: "Concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Concat3"
  top: "Convolution7"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise6"
  type: "ConvolutionDepthwise"
  bottom: "Convolution7"
  top: "ConvolutionDepthwise6"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise6"
  top: "ConvolutionDepthwise6"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "ConvolutionDepthwise6"
  top: "ConvolutionDepthwise6"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "ConvolutionDepthwise6"
  top: "ConvolutionDepthwise6"
}
layer {
  name: "Concat4"
  type: "Concat"
  bottom: "Concat3"
  bottom: "ConvolutionDepthwise6"
  top: "Concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Concat4"
  top: "Convolution8"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "BatchNorm12"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "BatchNorm12"
  top: "BatchNorm12"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "BatchNorm12"
  top: "ReLU8"
}
layer {
  name: "Pooling2"
  type: "Pooling"
  bottom: "ReLU8"
  top: "Pooling2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Pooling2"
  top: "Convolution9"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise7"
  type: "ConvolutionDepthwise"
  bottom: "Convolution9"
  top: "ConvolutionDepthwise7"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise7"
  top: "ConvolutionDepthwise7"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "ConvolutionDepthwise7"
  top: "ConvolutionDepthwise7"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "ConvolutionDepthwise7"
  top: "ConvolutionDepthwise7"
}
layer {
  name: "Concat5"
  type: "Concat"
  bottom: "Pooling2"
  bottom: "ConvolutionDepthwise7"
  top: "Concat5"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Concat5"
  top: "Convolution10"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise8"
  type: "ConvolutionDepthwise"
  bottom: "Convolution10"
  top: "ConvolutionDepthwise8"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise8"
  top: "ConvolutionDepthwise8"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "ConvolutionDepthwise8"
  top: "ConvolutionDepthwise8"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "ConvolutionDepthwise8"
  top: "ConvolutionDepthwise8"
}
layer {
  name: "Concat6"
  type: "Concat"
  bottom: "Concat5"
  bottom: "ConvolutionDepthwise8"
  top: "Concat6"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Concat6"
  top: "Convolution11"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise9"
  type: "ConvolutionDepthwise"
  bottom: "Convolution11"
  top: "ConvolutionDepthwise9"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise9"
  top: "ConvolutionDepthwise9"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "ConvolutionDepthwise9"
  top: "ConvolutionDepthwise9"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "ConvolutionDepthwise9"
  top: "ConvolutionDepthwise9"
}
layer {
  name: "Concat7"
  type: "Concat"
  bottom: "Concat6"
  bottom: "ConvolutionDepthwise9"
  top: "Concat7"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Concat7"
  top: "Convolution12"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise10"
  type: "ConvolutionDepthwise"
  bottom: "Convolution12"
  top: "ConvolutionDepthwise10"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise10"
  top: "ConvolutionDepthwise10"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "ConvolutionDepthwise10"
  top: "ConvolutionDepthwise10"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "ConvolutionDepthwise10"
  top: "ConvolutionDepthwise10"
}
layer {
  name: "Concat8"
  type: "Concat"
  bottom: "Concat7"
  bottom: "ConvolutionDepthwise10"
  top: "Concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Concat8"
  top: "Convolution13"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise11"
  type: "ConvolutionDepthwise"
  bottom: "Convolution13"
  top: "ConvolutionDepthwise11"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise11"
  top: "ConvolutionDepthwise11"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "ConvolutionDepthwise11"
  top: "ConvolutionDepthwise11"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "ConvolutionDepthwise11"
  top: "ConvolutionDepthwise11"
}
layer {
  name: "Concat9"
  type: "Concat"
  bottom: "Concat8"
  bottom: "ConvolutionDepthwise11"
  top: "Concat9"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Concat9"
  top: "Convolution14"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise12"
  type: "ConvolutionDepthwise"
  bottom: "Convolution14"
  top: "ConvolutionDepthwise12"
  convolution_param {
    num_output: 48
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise12"
  top: "ConvolutionDepthwise12"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "ConvolutionDepthwise12"
  top: "ConvolutionDepthwise12"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "ConvolutionDepthwise12"
  top: "ConvolutionDepthwise12"
}
layer {
  name: "Concat10"
  type: "Concat"
  bottom: "Concat9"
  bottom: "ConvolutionDepthwise12"
  top: "Concat10"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Concat10"
  top: "Convolution15"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "BatchNorm25"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "BatchNorm25"
  top: "BatchNorm25"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "First"
  type: "ReLU"
  bottom: "BatchNorm25"
  top: "First"
}
layer {
  name: "Pooling3"
  type: "Pooling"
  bottom: "First"
  top: "Pooling3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Pooling3"
  top: "Convolution16"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "BatchNorm26"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "BatchNorm26"
  top: "BatchNorm26"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "BatchNorm26"
  top: "BatchNorm26"
}
layer {
  name: "Pooling4"
  type: "Pooling"
  bottom: "First"
  top: "Pooling4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Pooling4"
  top: "Convolution17"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise13"
  type: "ConvolutionDepthwise"
  bottom: "Convolution17"
  top: "ConvolutionDepthwise13"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise13"
  top: "ConvolutionDepthwise13"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "ConvolutionDepthwise13"
  top: "ConvolutionDepthwise13"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "ConvolutionDepthwise13"
  top: "ConvolutionDepthwise13"
}
layer {
  name: "Concat11"
  type: "Concat"
  bottom: "Pooling4"
  bottom: "ConvolutionDepthwise13"
  top: "Concat11"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Concat11"
  top: "Convolution18"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise14"
  type: "ConvolutionDepthwise"
  bottom: "Convolution18"
  top: "ConvolutionDepthwise14"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise14"
  top: "ConvolutionDepthwise14"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "ConvolutionDepthwise14"
  top: "ConvolutionDepthwise14"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "ConvolutionDepthwise14"
  top: "ConvolutionDepthwise14"
}
layer {
  name: "Concat12"
  type: "Concat"
  bottom: "Concat11"
  bottom: "ConvolutionDepthwise14"
  top: "Concat12"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Concat12"
  top: "Convolution19"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise15"
  type: "ConvolutionDepthwise"
  bottom: "Convolution19"
  top: "ConvolutionDepthwise15"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise15"
  top: "ConvolutionDepthwise15"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale32"
  type: "Scale"
  bottom: "ConvolutionDepthwise15"
  top: "ConvolutionDepthwise15"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "ConvolutionDepthwise15"
  top: "ConvolutionDepthwise15"
}
layer {
  name: "Concat13"
  type: "Concat"
  bottom: "Concat12"
  bottom: "ConvolutionDepthwise15"
  top: "Concat13"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Concat13"
  top: "Convolution20"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm33"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale33"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise16"
  type: "ConvolutionDepthwise"
  bottom: "Convolution20"
  top: "ConvolutionDepthwise16"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm34"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise16"
  top: "ConvolutionDepthwise16"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale34"
  type: "Scale"
  bottom: "ConvolutionDepthwise16"
  top: "ConvolutionDepthwise16"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "ConvolutionDepthwise16"
  top: "ConvolutionDepthwise16"
}
layer {
  name: "Concat14"
  type: "Concat"
  bottom: "Concat13"
  bottom: "ConvolutionDepthwise16"
  top: "Concat14"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Concat14"
  top: "Convolution21"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm35"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale35"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise17"
  type: "ConvolutionDepthwise"
  bottom: "Convolution21"
  top: "ConvolutionDepthwise17"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm36"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise17"
  top: "ConvolutionDepthwise17"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale36"
  type: "Scale"
  bottom: "ConvolutionDepthwise17"
  top: "ConvolutionDepthwise17"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "ConvolutionDepthwise17"
  top: "ConvolutionDepthwise17"
}
layer {
  name: "Concat15"
  type: "Concat"
  bottom: "Concat14"
  bottom: "ConvolutionDepthwise17"
  top: "Concat15"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Concat15"
  top: "Convolution22"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm37"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale37"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise18"
  type: "ConvolutionDepthwise"
  bottom: "Convolution22"
  top: "ConvolutionDepthwise18"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm38"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise18"
  top: "ConvolutionDepthwise18"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale38"
  type: "Scale"
  bottom: "ConvolutionDepthwise18"
  top: "ConvolutionDepthwise18"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "ConvolutionDepthwise18"
  top: "ConvolutionDepthwise18"
}
layer {
  name: "Concat16"
  type: "Concat"
  bottom: "Concat15"
  bottom: "ConvolutionDepthwise18"
  top: "Concat16"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Concat16"
  top: "Convolution23"
  convolution_param {
    num_output: 256
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm39"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "BatchNorm39"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale39"
  type: "Scale"
  bottom: "BatchNorm39"
  top: "BatchNorm39"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "BatchNorm39"
  top: "ReLU22"
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "ReLU22"
  top: "Convolution24"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm40"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale40"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise19"
  type: "ConvolutionDepthwise"
  bottom: "Convolution24"
  top: "ConvolutionDepthwise19"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm41"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise19"
  top: "ConvolutionDepthwise19"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale41"
  type: "Scale"
  bottom: "ConvolutionDepthwise19"
  top: "ConvolutionDepthwise19"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "ConvolutionDepthwise19"
  top: "ConvolutionDepthwise19"
}
layer {
  name: "Concat17"
  type: "Concat"
  bottom: "ReLU22"
  bottom: "ConvolutionDepthwise19"
  top: "Concat17"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Concat17"
  top: "Convolution25"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm42"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale42"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise20"
  type: "ConvolutionDepthwise"
  bottom: "Convolution25"
  top: "ConvolutionDepthwise20"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm43"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise20"
  top: "ConvolutionDepthwise20"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale43"
  type: "Scale"
  bottom: "ConvolutionDepthwise20"
  top: "ConvolutionDepthwise20"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "ConvolutionDepthwise20"
  top: "ConvolutionDepthwise20"
}
layer {
  name: "Concat18"
  type: "Concat"
  bottom: "Concat17"
  bottom: "ConvolutionDepthwise20"
  top: "Concat18"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Concat18"
  top: "Convolution26"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm44"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale44"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise21"
  type: "ConvolutionDepthwise"
  bottom: "Convolution26"
  top: "ConvolutionDepthwise21"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm45"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise21"
  top: "ConvolutionDepthwise21"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale45"
  type: "Scale"
  bottom: "ConvolutionDepthwise21"
  top: "ConvolutionDepthwise21"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "ConvolutionDepthwise21"
  top: "ConvolutionDepthwise21"
}
layer {
  name: "Concat19"
  type: "Concat"
  bottom: "Concat18"
  bottom: "ConvolutionDepthwise21"
  top: "Concat19"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Concat19"
  top: "Convolution27"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm46"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale46"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise22"
  type: "ConvolutionDepthwise"
  bottom: "Convolution27"
  top: "ConvolutionDepthwise22"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm47"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise22"
  top: "ConvolutionDepthwise22"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale47"
  type: "Scale"
  bottom: "ConvolutionDepthwise22"
  top: "ConvolutionDepthwise22"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "ConvolutionDepthwise22"
  top: "ConvolutionDepthwise22"
}
layer {
  name: "Concat20"
  type: "Concat"
  bottom: "Concat19"
  bottom: "ConvolutionDepthwise22"
  top: "Concat20"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Concat20"
  top: "Convolution28"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm48"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale48"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise23"
  type: "ConvolutionDepthwise"
  bottom: "Convolution28"
  top: "ConvolutionDepthwise23"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm49"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise23"
  top: "ConvolutionDepthwise23"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale49"
  type: "Scale"
  bottom: "ConvolutionDepthwise23"
  top: "ConvolutionDepthwise23"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "ConvolutionDepthwise23"
  top: "ConvolutionDepthwise23"
}
layer {
  name: "Concat21"
  type: "Concat"
  bottom: "Concat20"
  bottom: "ConvolutionDepthwise23"
  top: "Concat21"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Concat21"
  top: "Convolution29"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm50"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale50"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ConvolutionDepthwise24"
  type: "ConvolutionDepthwise"
  bottom: "Convolution29"
  top: "ConvolutionDepthwise24"
  convolution_param {
    num_output: 80
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm51"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise24"
  top: "ConvolutionDepthwise24"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale51"
  type: "Scale"
  bottom: "ConvolutionDepthwise24"
  top: "ConvolutionDepthwise24"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "ConvolutionDepthwise24"
  top: "ConvolutionDepthwise24"
}
layer {
  name: "Concat22"
  type: "Concat"
  bottom: "Concat21"
  bottom: "ConvolutionDepthwise24"
  top: "Concat22"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Concat22"
  top: "Convolution30"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm52"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "BatchNorm52"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale52"
  type: "Scale"
  bottom: "BatchNorm52"
  top: "BatchNorm52"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "BatchNorm52"
  top: "ReLU29"
}
layer {
  name: "Second"
  type: "Concat"
  bottom: "BatchNorm26"
  bottom: "ReLU29"
  top: "Second"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling5"
  type: "Pooling"
  bottom: "Second"
  top: "Pooling5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Pooling5"
  top: "Convolution31"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm53"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "BatchNorm53"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale53"
  type: "Scale"
  bottom: "BatchNorm53"
  top: "BatchNorm53"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU30"
  type: "ReLU"
  bottom: "BatchNorm53"
  top: "BatchNorm53"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Second"
  top: "Convolution32"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ConvolutionDepthwise25"
  type: "ConvolutionDepthwise"
  bottom: "Convolution32"
  top: "ConvolutionDepthwise25"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm54"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise25"
  top: "BatchNorm54"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale54"
  type: "Scale"
  bottom: "BatchNorm54"
  top: "BatchNorm54"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU31"
  type: "ReLU"
  bottom: "BatchNorm54"
  top: "BatchNorm54"
}
layer {
  name: "Third"
  type: "Concat"
  bottom: "BatchNorm53"
  bottom: "BatchNorm54"
  top: "Third"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling6"
  type: "Pooling"
  bottom: "Third"
  top: "Pooling6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution33"
  type: "Convolution"
  bottom: "Pooling6"
  top: "Convolution33"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm55"
  type: "BatchNorm"
  bottom: "Convolution33"
  top: "BatchNorm55"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale55"
  type: "Scale"
  bottom: "BatchNorm55"
  top: "BatchNorm55"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU32"
  type: "ReLU"
  bottom: "BatchNorm55"
  top: "BatchNorm55"
}
layer {
  name: "Convolution34"
  type: "Convolution"
  bottom: "Third"
  top: "Convolution34"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ConvolutionDepthwise26"
  type: "ConvolutionDepthwise"
  bottom: "Convolution34"
  top: "ConvolutionDepthwise26"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm56"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise26"
  top: "BatchNorm56"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale56"
  type: "Scale"
  bottom: "BatchNorm56"
  top: "BatchNorm56"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU33"
  type: "ReLU"
  bottom: "BatchNorm56"
  top: "BatchNorm56"
}
layer {
  name: "Fourth"
  type: "Concat"
  bottom: "BatchNorm55"
  bottom: "BatchNorm56"
  top: "Fourth"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling7"
  type: "Pooling"
  bottom: "Fourth"
  top: "Pooling7"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution35"
  type: "Convolution"
  bottom: "Pooling7"
  top: "Convolution35"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm57"
  type: "BatchNorm"
  bottom: "Convolution35"
  top: "BatchNorm57"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale57"
  type: "Scale"
  bottom: "BatchNorm57"
  top: "BatchNorm57"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU34"
  type: "ReLU"
  bottom: "BatchNorm57"
  top: "BatchNorm57"
}
layer {
  name: "Convolution36"
  type: "Convolution"
  bottom: "Fourth"
  top: "Convolution36"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ConvolutionDepthwise27"
  type: "ConvolutionDepthwise"
  bottom: "Convolution36"
  top: "ConvolutionDepthwise27"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm58"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise27"
  top: "BatchNorm58"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale58"
  type: "Scale"
  bottom: "BatchNorm58"
  top: "BatchNorm58"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU35"
  type: "ReLU"
  bottom: "BatchNorm58"
  top: "BatchNorm58"
}
layer {
  name: "Fifth"
  type: "Concat"
  bottom: "BatchNorm57"
  bottom: "BatchNorm58"
  top: "Fifth"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Pooling8"
  type: "Pooling"
  bottom: "Fifth"
  top: "Pooling8"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "Convolution37"
  type: "Convolution"
  bottom: "Pooling8"
  top: "Convolution37"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm59"
  type: "BatchNorm"
  bottom: "Convolution37"
  top: "BatchNorm59"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale59"
  type: "Scale"
  bottom: "BatchNorm59"
  top: "BatchNorm59"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU36"
  type: "ReLU"
  bottom: "BatchNorm59"
  top: "BatchNorm59"
}
layer {
  name: "Convolution38"
  type: "Convolution"
  bottom: "Fifth"
  top: "Convolution38"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "ConvolutionDepthwise28"
  type: "ConvolutionDepthwise"
  bottom: "Convolution38"
  top: "ConvolutionDepthwise28"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "BatchNorm60"
  type: "BatchNorm"
  bottom: "ConvolutionDepthwise28"
  top: "BatchNorm60"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "Scale60"
  type: "Scale"
  bottom: "BatchNorm60"
  top: "BatchNorm60"
  scale_param {
    filler {
      value: 1.0
    }
    bias_term: true
    bias_filler {
      value: 0.0
    }
  }
}
layer {
  name: "ReLU37"
  type: "ReLU"
  bottom: "BatchNorm60"
  top: "BatchNorm60"
}
layer {
  name: "Sixth"
  type: "Concat"
  bottom: "BatchNorm59"
  bottom: "BatchNorm60"
  top: "Sixth"
  concat_param {
    axis: 1
  }
}
layer {
  name: "Upsample1"
  type: "Upsample"
  bottom: "Fifth"
  bottom: "Sixth"
  top: "Upsample1"
  propagate_down: false
  propagate_down: true
}
layer {
  name: "ConvolutionDepthwise29"
  type: "ConvolutionDepthwise"
  bottom: "Upsample1"
  top: "ConvolutionDepthwise29"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "ConvolutionDepthwise29"
  bottom: "Fifth"
  top: "Eltwise1"
}
layer {
  name: "Fifth_out"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Upsample2"
  type: "Upsample"
  bottom: "Fourth"
  bottom: "Eltwise1"
  top: "Upsample2"
  propagate_down: false
  propagate_down: true
}
layer {
  name: "ConvolutionDepthwise30"
  type: "ConvolutionDepthwise"
  bottom: "Upsample2"
  top: "ConvolutionDepthwise30"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "ConvolutionDepthwise30"
  bottom: "Fourth"
  top: "Eltwise2"
}
layer {
  name: "Fourth_out"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Upsample3"
  type: "Upsample"
  bottom: "Third"
  bottom: "Eltwise2"
  top: "Upsample3"
  propagate_down: false
  propagate_down: true
}
layer {
  name: "ConvolutionDepthwise31"
  type: "ConvolutionDepthwise"
  bottom: "Upsample3"
  top: "ConvolutionDepthwise31"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "ConvolutionDepthwise31"
  bottom: "Third"
  top: "Eltwise3"
}
layer {
  name: "Third_out"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Upsample4"
  type: "Upsample"
  bottom: "Second"
  bottom: "Eltwise3"
  top: "Upsample4"
  propagate_down: false
  propagate_down: true
}
layer {
  name: "ConvolutionDepthwise32"
  type: "ConvolutionDepthwise"
  bottom: "Upsample4"
  top: "ConvolutionDepthwise32"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "ConvolutionDepthwise32"
  bottom: "Second"
  top: "Eltwise4"
}
layer {
  name: "Second_out"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Upsample5"
  type: "Upsample"
  bottom: "First"
  bottom: "Eltwise4"
  top: "Upsample5"
  propagate_down: false
  propagate_down: true
}
layer {
  name: "ConvolutionDepthwise33"
  type: "ConvolutionDepthwise"
  bottom: "Upsample5"
  top: "ConvolutionDepthwise33"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Convolution39"
  type: "Convolution"
  bottom: "ConvolutionDepthwise33"
  top: "Convolution39"
  convolution_param {
    num_output: 128
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution39"
  bottom: "First"
  top: "Eltwise5"
}
layer {
  name: "First_out"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "First_out_norm"
  type: "Normalize"
  bottom: "Eltwise5"
  top: "First_out_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "First_out_norm_mbox_loc_1x1_conv"
  type: "Convolution"
  bottom: "First_out_norm"
  top: "First_out_norm_mbox_loc_1x1_conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.009999999776482582
    }
  }
}
layer {
  name: "First_out_norm_mbox_loc_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "First_out_norm_mbox_loc_1x1_conv"
  top: "First_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "First_out_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "First_out_norm_mbox_loc_dw_conv"
  top: "First_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "First_out_norm_mbox_loc_sb"
  type: "Scale"
  bottom: "First_out_norm_mbox_loc_dw_conv"
  top: "First_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "First_out_norm_mbox_loc_sb_perm"
  type: "Permute"
  bottom: "First_out_norm_mbox_loc_dw_conv"
  top: "First_out_norm_mbox_loc_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "First_out_norm_mbox_loc_sb_flat"
  type: "Flatten"
  bottom: "First_out_norm_mbox_loc_sb_perm"
  top: "First_out_norm_mbox_loc_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "First_out_norm_mbox_conf_1x1_conv"
  type: "Convolution"
  bottom: "First_out_norm"
  top: "First_out_norm_mbox_conf_1x1_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.10000000149011612
    }
  }
}
layer {
  name: "First_out_norm_mbox_conf_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "First_out_norm_mbox_conf_1x1_conv"
  top: "First_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "First_out_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "First_out_norm_mbox_conf_dw_conv"
  top: "First_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "First_out_norm_mbox_conf_sb"
  type: "Scale"
  bottom: "First_out_norm_mbox_conf_dw_conv"
  top: "First_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "First_out_norm_mbox_conf_sb_perm"
  type: "Permute"
  bottom: "First_out_norm_mbox_conf_dw_conv"
  top: "First_out_norm_mbox_conf_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "First_out_norm_mbox_conf_sb_flat"
  type: "Flatten"
  bottom: "First_out_norm_mbox_conf_sb_perm"
  top: "First_out_norm_mbox_conf_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "First_out_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "First_out_norm"
  bottom: "data"
  top: "First_out_norm_mbox_priorbox"
  prior_box_param {
    min_size: 30.0
    max_size: 60.0
    aspect_ratio: 2.0
    flip: true
    clip: false
    variance: 0.10000000149011612
    variance: 0.10000000149011612
    variance: 0.20000000298023224
    variance: 0.20000000298023224
    step: 8.0
    offset: 0.5
  }
}
layer {
  name: "Second_out_norm"
  type: "Normalize"
  bottom: "Eltwise4"
  top: "Second_out_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Second_out_norm_mbox_loc_1x1_conv"
  type: "Convolution"
  bottom: "Second_out_norm"
  top: "Second_out_norm_mbox_loc_1x1_conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.009999999776482582
    }
  }
}
layer {
  name: "Second_out_norm_mbox_loc_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Second_out_norm_mbox_loc_1x1_conv"
  top: "Second_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Second_out_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Second_out_norm_mbox_loc_dw_conv"
  top: "Second_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Second_out_norm_mbox_loc_sb"
  type: "Scale"
  bottom: "Second_out_norm_mbox_loc_dw_conv"
  top: "Second_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Second_out_norm_mbox_loc_sb_perm"
  type: "Permute"
  bottom: "Second_out_norm_mbox_loc_dw_conv"
  top: "Second_out_norm_mbox_loc_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Second_out_norm_mbox_loc_sb_flat"
  type: "Flatten"
  bottom: "Second_out_norm_mbox_loc_sb_perm"
  top: "Second_out_norm_mbox_loc_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Second_out_norm_mbox_conf_1x1_conv"
  type: "Convolution"
  bottom: "Second_out_norm"
  top: "Second_out_norm_mbox_conf_1x1_conv"
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.10000000149011612
    }
  }
}
layer {
  name: "Second_out_norm_mbox_conf_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Second_out_norm_mbox_conf_1x1_conv"
  top: "Second_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Second_out_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Second_out_norm_mbox_conf_dw_conv"
  top: "Second_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Second_out_norm_mbox_conf_sb"
  type: "Scale"
  bottom: "Second_out_norm_mbox_conf_dw_conv"
  top: "Second_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Second_out_norm_mbox_conf_sb_perm"
  type: "Permute"
  bottom: "Second_out_norm_mbox_conf_dw_conv"
  top: "Second_out_norm_mbox_conf_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Second_out_norm_mbox_conf_sb_flat"
  type: "Flatten"
  bottom: "Second_out_norm_mbox_conf_sb_perm"
  top: "Second_out_norm_mbox_conf_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Second_out_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Second_out_norm"
  bottom: "data"
  top: "Second_out_norm_mbox_priorbox"
  prior_box_param {
    min_size: 60.0
    max_size: 111.0
    aspect_ratio: 2.0
    aspect_ratio: 3.0
    flip: true
    clip: false
    variance: 0.10000000149011612
    variance: 0.10000000149011612
    variance: 0.20000000298023224
    variance: 0.20000000298023224
    step: 16.0
    offset: 0.5
  }
}
layer {
  name: "Third_out_norm"
  type: "Normalize"
  bottom: "Eltwise3"
  top: "Third_out_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Third_out_norm_mbox_loc_1x1_conv"
  type: "Convolution"
  bottom: "Third_out_norm"
  top: "Third_out_norm_mbox_loc_1x1_conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.009999999776482582
    }
  }
}
layer {
  name: "Third_out_norm_mbox_loc_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Third_out_norm_mbox_loc_1x1_conv"
  top: "Third_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Third_out_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Third_out_norm_mbox_loc_dw_conv"
  top: "Third_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Third_out_norm_mbox_loc_sb"
  type: "Scale"
  bottom: "Third_out_norm_mbox_loc_dw_conv"
  top: "Third_out_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Third_out_norm_mbox_loc_sb_perm"
  type: "Permute"
  bottom: "Third_out_norm_mbox_loc_dw_conv"
  top: "Third_out_norm_mbox_loc_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Third_out_norm_mbox_loc_sb_flat"
  type: "Flatten"
  bottom: "Third_out_norm_mbox_loc_sb_perm"
  top: "Third_out_norm_mbox_loc_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Third_out_norm_mbox_conf_1x1_conv"
  type: "Convolution"
  bottom: "Third_out_norm"
  top: "Third_out_norm_mbox_conf_1x1_conv"
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.10000000149011612
    }
  }
}
layer {
  name: "Third_out_norm_mbox_conf_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Third_out_norm_mbox_conf_1x1_conv"
  top: "Third_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Third_out_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Third_out_norm_mbox_conf_dw_conv"
  top: "Third_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Third_out_norm_mbox_conf_sb"
  type: "Scale"
  bottom: "Third_out_norm_mbox_conf_dw_conv"
  top: "Third_out_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Third_out_norm_mbox_conf_sb_perm"
  type: "Permute"
  bottom: "Third_out_norm_mbox_conf_dw_conv"
  top: "Third_out_norm_mbox_conf_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Third_out_norm_mbox_conf_sb_flat"
  type: "Flatten"
  bottom: "Third_out_norm_mbox_conf_sb_perm"
  top: "Third_out_norm_mbox_conf_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Third_out_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Third_out_norm"
  bottom: "data"
  top: "Third_out_norm_mbox_priorbox"
  prior_box_param {
    min_size: 111.0
    max_size: 162.0
    aspect_ratio: 2.0
    aspect_ratio: 3.0
    flip: true
    clip: false
    variance: 0.10000000149011612
    variance: 0.10000000149011612
    variance: 0.20000000298023224
    variance: 0.20000000298023224
    step: 32.0
    offset: 0.5
  }
}
layer {
  name: "Fourth_norm"
  type: "Normalize"
  bottom: "Fourth"
  top: "Fourth_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Fourth_norm_mbox_loc_1x1_conv"
  type: "Convolution"
  bottom: "Fourth_norm"
  top: "Fourth_norm_mbox_loc_1x1_conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.009999999776482582
    }
  }
}
layer {
  name: "Fourth_norm_mbox_loc_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Fourth_norm_mbox_loc_1x1_conv"
  top: "Fourth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 24
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Fourth_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Fourth_norm_mbox_loc_dw_conv"
  top: "Fourth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Fourth_norm_mbox_loc_sb"
  type: "Scale"
  bottom: "Fourth_norm_mbox_loc_dw_conv"
  top: "Fourth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fourth_norm_mbox_loc_sb_perm"
  type: "Permute"
  bottom: "Fourth_norm_mbox_loc_dw_conv"
  top: "Fourth_norm_mbox_loc_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fourth_norm_mbox_loc_sb_flat"
  type: "Flatten"
  bottom: "Fourth_norm_mbox_loc_sb_perm"
  top: "Fourth_norm_mbox_loc_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fourth_norm_mbox_conf_1x1_conv"
  type: "Convolution"
  bottom: "Fourth_norm"
  top: "Fourth_norm_mbox_conf_1x1_conv"
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.10000000149011612
    }
  }
}
layer {
  name: "Fourth_norm_mbox_conf_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Fourth_norm_mbox_conf_1x1_conv"
  top: "Fourth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 12
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Fourth_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Fourth_norm_mbox_conf_dw_conv"
  top: "Fourth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Fourth_norm_mbox_conf_sb"
  type: "Scale"
  bottom: "Fourth_norm_mbox_conf_dw_conv"
  top: "Fourth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fourth_norm_mbox_conf_sb_perm"
  type: "Permute"
  bottom: "Fourth_norm_mbox_conf_dw_conv"
  top: "Fourth_norm_mbox_conf_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fourth_norm_mbox_conf_sb_flat"
  type: "Flatten"
  bottom: "Fourth_norm_mbox_conf_sb_perm"
  top: "Fourth_norm_mbox_conf_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fourth_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Fourth_norm"
  bottom: "data"
  top: "Fourth_norm_mbox_priorbox"
  prior_box_param {
    min_size: 162.0
    max_size: 213.0
    aspect_ratio: 2.0
    aspect_ratio: 3.0
    flip: true
    clip: false
    variance: 0.10000000149011612
    variance: 0.10000000149011612
    variance: 0.20000000298023224
    variance: 0.20000000298023224
    step: 64.0
    offset: 0.5
  }
}
layer {
  name: "Fifth_norm"
  type: "Normalize"
  bottom: "Fifth"
  top: "Fifth_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Fifth_norm_mbox_loc_1x1_conv"
  type: "Convolution"
  bottom: "Fifth_norm"
  top: "Fifth_norm_mbox_loc_1x1_conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.009999999776482582
    }
  }
}
layer {
  name: "Fifth_norm_mbox_loc_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Fifth_norm_mbox_loc_1x1_conv"
  top: "Fifth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Fifth_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Fifth_norm_mbox_loc_dw_conv"
  top: "Fifth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Fifth_norm_mbox_loc_sb"
  type: "Scale"
  bottom: "Fifth_norm_mbox_loc_dw_conv"
  top: "Fifth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fifth_norm_mbox_loc_sb_perm"
  type: "Permute"
  bottom: "Fifth_norm_mbox_loc_dw_conv"
  top: "Fifth_norm_mbox_loc_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fifth_norm_mbox_loc_sb_flat"
  type: "Flatten"
  bottom: "Fifth_norm_mbox_loc_sb_perm"
  top: "Fifth_norm_mbox_loc_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fifth_norm_mbox_conf_1x1_conv"
  type: "Convolution"
  bottom: "Fifth_norm"
  top: "Fifth_norm_mbox_conf_1x1_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.10000000149011612
    }
  }
}
layer {
  name: "Fifth_norm_mbox_conf_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Fifth_norm_mbox_conf_1x1_conv"
  top: "Fifth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Fifth_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Fifth_norm_mbox_conf_dw_conv"
  top: "Fifth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Fifth_norm_mbox_conf_sb"
  type: "Scale"
  bottom: "Fifth_norm_mbox_conf_dw_conv"
  top: "Fifth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Fifth_norm_mbox_conf_sb_perm"
  type: "Permute"
  bottom: "Fifth_norm_mbox_conf_dw_conv"
  top: "Fifth_norm_mbox_conf_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Fifth_norm_mbox_conf_sb_flat"
  type: "Flatten"
  bottom: "Fifth_norm_mbox_conf_sb_perm"
  top: "Fifth_norm_mbox_conf_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Fifth_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Fifth_norm"
  bottom: "data"
  top: "Fifth_norm_mbox_priorbox"
  prior_box_param {
    min_size: 213.0
    max_size: 264.0
    aspect_ratio: 2.0
    flip: true
    clip: false
    variance: 0.10000000149011612
    variance: 0.10000000149011612
    variance: 0.20000000298023224
    variance: 0.20000000298023224
    step: 100.0
    offset: 0.5
  }
}
layer {
  name: "Sixth_norm"
  type: "Normalize"
  bottom: "Sixth"
  top: "Sixth_norm"
  norm_param {
    across_spatial: false
    scale_filler {
      type: "constant"
      value: 20.0
    }
    channel_shared: false
  }
}
layer {
  name: "Sixth_norm_mbox_loc_1x1_conv"
  type: "Convolution"
  bottom: "Sixth_norm"
  top: "Sixth_norm_mbox_loc_1x1_conv"
  param {
    lr_mult: 1.0
    decay_mult: 1.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.009999999776482582
    }
  }
}
layer {
  name: "Sixth_norm_mbox_loc_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Sixth_norm_mbox_loc_1x1_conv"
  top: "Sixth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Sixth_norm_mbox_loc_bn"
  type: "BatchNorm"
  bottom: "Sixth_norm_mbox_loc_dw_conv"
  top: "Sixth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Sixth_norm_mbox_loc_sb"
  type: "Scale"
  bottom: "Sixth_norm_mbox_loc_dw_conv"
  top: "Sixth_norm_mbox_loc_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Sixth_norm_mbox_loc_sb_perm"
  type: "Permute"
  bottom: "Sixth_norm_mbox_loc_dw_conv"
  top: "Sixth_norm_mbox_loc_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Sixth_norm_mbox_loc_sb_flat"
  type: "Flatten"
  bottom: "Sixth_norm_mbox_loc_sb_perm"
  top: "Sixth_norm_mbox_loc_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Sixth_norm_mbox_conf_1x1_conv"
  type: "Convolution"
  bottom: "Sixth_norm"
  top: "Sixth_norm_mbox_conf_1x1_conv"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.10000000149011612
    }
  }
}
layer {
  name: "Sixth_norm_mbox_conf_dw_conv"
  type: "ConvolutionDepthwise"
  bottom: "Sixth_norm_mbox_conf_1x1_conv"
  top: "Sixth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "Sixth_norm_mbox_conf_bn"
  type: "BatchNorm"
  bottom: "Sixth_norm_mbox_conf_dw_conv"
  top: "Sixth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  batch_norm_param {
    moving_average_fraction: 0.9990000128746033
    eps: 0.0010000000474974513
  }
}
layer {
  name: "Sixth_norm_mbox_conf_sb"
  type: "Scale"
  bottom: "Sixth_norm_mbox_conf_dw_conv"
  top: "Sixth_norm_mbox_conf_dw_conv"
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 1.0
    decay_mult: 0.0
  }
  scale_param {
    filler {
      type: "constant"
      value: 1.0
    }
    bias_term: true
    bias_filler {
      type: "constant"
      value: 0.0
    }
  }
}
layer {
  name: "Sixth_norm_mbox_conf_sb_perm"
  type: "Permute"
  bottom: "Sixth_norm_mbox_conf_dw_conv"
  top: "Sixth_norm_mbox_conf_sb_perm"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "Sixth_norm_mbox_conf_sb_flat"
  type: "Flatten"
  bottom: "Sixth_norm_mbox_conf_sb_perm"
  top: "Sixth_norm_mbox_conf_sb_flat"
  flatten_param {
    axis: 1
  }
}
layer {
  name: "Sixth_norm_mbox_priorbox"
  type: "PriorBox"
  bottom: "Sixth_norm"
  bottom: "data"
  top: "Sixth_norm_mbox_priorbox"
  prior_box_param {
    min_size: 264.0
    max_size: 315.0
    aspect_ratio: 2.0
    flip: true
    clip: false
    variance: 0.10000000149011612
    variance: 0.10000000149011612
    variance: 0.20000000298023224
    variance: 0.20000000298023224
    step: 300.0
    offset: 0.5
  }
}
layer {
  name: "mbox_loc"
  type: "Concat"
  bottom: "First_out_norm_mbox_loc_sb_flat"
  bottom: "Second_out_norm_mbox_loc_sb_flat"
  bottom: "Third_out_norm_mbox_loc_sb_flat"
  bottom: "Fourth_norm_mbox_loc_sb_flat"
  bottom: "Fifth_norm_mbox_loc_sb_flat"
  bottom: "Sixth_norm_mbox_loc_sb_flat"
  top: "mbox_loc"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_conf"
  type: "Concat"
  bottom: "First_out_norm_mbox_conf_sb_flat"
  bottom: "Second_out_norm_mbox_conf_sb_flat"
  bottom: "Third_out_norm_mbox_conf_sb_flat"
  bottom: "Fourth_norm_mbox_conf_sb_flat"
  bottom: "Fifth_norm_mbox_conf_sb_flat"
  bottom: "Sixth_norm_mbox_conf_sb_flat"
  top: "mbox_conf"
  concat_param {
    axis: 1
  }
}
layer {
  name: "mbox_priorbox"
  type: "Concat"
  bottom: "First_out_norm_mbox_priorbox"
  bottom: "Second_out_norm_mbox_priorbox"
  bottom: "Third_out_norm_mbox_priorbox"
  bottom: "Fourth_norm_mbox_priorbox"
  bottom: "Fifth_norm_mbox_priorbox"
  bottom: "Sixth_norm_mbox_priorbox"
  top: "mbox_priorbox"
  concat_param {
    axis: 2
  }
}
layer {
  name: "mbox_loss"
  type: "MultiBoxLoss"
  bottom: "mbox_loc"
  bottom: "mbox_conf"
  bottom: "mbox_priorbox"
  bottom: "label"
  top: "mbox_loss"
  include {
    phase: TRAIN
  }
  propagate_down: true
  propagate_down: true
  propagate_down: false
  propagate_down: false
  loss_param {
    normalization: VALID
  }
  multibox_loss_param {
    loc_loss_type: SMOOTH_L1
    conf_loss_type: SOFTMAX
    loc_weight: 1.0
    num_classes: 2
    share_location: true
    match_type: PER_PREDICTION
    overlap_threshold: 0.5
    use_prior_for_matching: true
    background_label_id: 0
    use_difficult_gt: true
    neg_pos_ratio: 3.0
    neg_overlap: 0.5
    code_type: CENTER_SIZE
    ignore_cross_boundary_bbox: false
    mining_type: MAX_NEGATIVE
    is_condition: false
  }
}

